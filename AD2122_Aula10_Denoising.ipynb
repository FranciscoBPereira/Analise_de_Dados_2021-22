{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"AD2122_Aula_Denoising.ipynb","provenance":[{"file_id":"1MMqyffqQR9bCa59FuHbcK8Ry5ECc0qIx","timestamp":1653657551919}],"collapsed_sections":[],"authorship_tag":"ABX9TyMhj0YN20kSBKXaZq+gGWOu"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"jRdUZw-iCFy-"},"outputs":[],"source":["# Python ≥3.5 is required\n","import sys\n","assert sys.version_info >= (3, 5)\n","\n","# Scikit-Learn ≥0.20 is required\n","import sklearn\n","assert sklearn.__version__ >= \"0.20\"\n","\n","try:\n","    # %tensorflow_version only exists in Colab.\n","    %tensorflow_version 2.x\n","except Exception:\n","    pass\n","\n","# TensorFlow ≥2.0 is required\n","import tensorflow as tf\n","assert tf.__version__ >= \"2.0\"\n","\n","# Common imports\n","import numpy as np\n","import os\n","\n","# to make this notebook's output stable across runs\n","np.random.seed(42)\n","\n","# To plot pretty figures\n","%matplotlib inline\n","import matplotlib as mpl\n","import matplotlib.pyplot as plt\n","mpl.rc('axes', labelsize=14)\n","mpl.rc('xtick', labelsize=12)\n","mpl.rc('ytick', labelsize=12)\n","\n","\n","# Ignore useless warnings (see SciPy issue #5998)\n","import warnings\n","warnings.filterwarnings(action=\"ignore\", message=\"^internal gelsd\")"]},{"cell_type":"code","source":["from sklearn.metrics import accuracy_score, precision_score, recall_score\n","from sklearn.model_selection import train_test_split\n","from tensorflow.keras import layers, losses\n","from tensorflow.keras.datasets import fashion_mnist\n","from tensorflow.keras.models import Model"],"metadata":{"id":"_3j-Rl0sCnnT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Obter o Dataset diretamente dos datasets disponíveis no Keras \n","# Neste exemplo os targets são irrelevantes, sendo carregadas apenas as imagens 28*28\n","\n","(x_train, _), (x_test, _) = fashion_mnist.load_data()"],"metadata":{"id":"3iRrDEIGCqqd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Normalizar as imagens e preparar para o input no autoencoder\n","\n","x_train = x_train.astype('float32') / 255.\n","x_test = x_test.astype('float32') / 255.\n","\n","x_train = x_train[..., tf.newaxis]\n","x_test = x_test[..., tf.newaxis]\n","\n","print(x_train.shape)\n","print(x_test.shape)"],"metadata":{"id":"5umc5xnECuff"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Criar uma versão das imagens com ruído aleatório. O fator de ruído define a força da perturbação adicionada\n","# Utiliza o método normal do tensorflow que devolve valores aleatórios seguindo uma distribuição normal\n","# https://www.tensorflow.org/api_docs/python/tf/random/normal\n","# Garante-se que os valores permanecem dentro do intervalo [0, 1]\n","\n","noise_factor = 0.2\n","x_train_noisy = x_train + noise_factor * tf.random.normal(shape=x_train.shape) \n","x_test_noisy = x_test + noise_factor * tf.random.normal(shape=x_test.shape) \n","\n","x_train_noisy = tf.clip_by_value(x_train_noisy, clip_value_min=0., clip_value_max=1.)\n","x_test_noisy = tf.clip_by_value(x_test_noisy, clip_value_min=0., clip_value_max=1.)"],"metadata":{"id":"PjCB9zmTCzah"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Visualização de algumas imagens originais e com ruído\n","# Pode alterar o valor da variável start para visualizar outros exemplos\n","\n","start= 10\n","\n","n = 10\n","plt.figure(figsize=(20, 6))\n","for i in range(n):\n","    ax = plt.subplot(2, n, i + 1)\n","    plt.title(\"original\")\n","    plt.imshow(tf.squeeze(x_test[i+start]))\n","    plt.gray()\n","    \n","    ax = plt.subplot(2, n, i + n + 1)\n","    plt.title(\"original + noise\")\n","    plt.imshow(tf.squeeze(x_test_noisy[i+start]))\n","    plt.gray()\n","    \n","plt.show()"],"metadata":{"id":"WELp1R53C8ps"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Completar a secção do Decoder. Deve utilizar camadas Conv2DTranspose parta efetuar o upsampling\n","# https://www.tensorflow.org/api_docs/python/tf/keras/layers/Conv2DTranspose\n","\n","class Denoise(Model):\n","  def __init__(self):\n","    super(Denoise, self).__init__()\n","    self.encoder = tf.keras.Sequential([\n","      layers.Input(shape=(28, 28, 1)),\n","      layers.Conv2D(16, (3, 3), activation='relu', padding='same', strides=2),\n","      layers.Conv2D(8, (3, 3), activation='relu', padding='same', strides=2)])\n","\n","    self.decoder = tf.keras.Sequential([\n","      \n","      # Completar com as camadas que permitam efetuar o upsampling\n","\n","      layers.Conv2D(1, kernel_size=(3, 3), activation='sigmoid', padding='same')])\n","\n","  def call(self, x):\n","    encoded = self.encoder(x)\n","    decoded = self.decoder(encoded)\n","    return decoded\n"],"metadata":{"id":"YLJybUXXDJqk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Criar um objeto Autoencoder\n","\n","tf.keras.backend.clear_session()\n","tf.random.set_seed(42)\n","np.random.seed(42)\n","\n","autoencoder = Denoise()"],"metadata":{"id":"ZvfQs2v5DO3R"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Compilar o modelo\n","# A loss vai corresponder à diferença entre a imagem produzida e a pretendida\n","\n","autoencoder.compile(optimizer='adam', loss=losses.MeanSquaredError())"],"metadata":{"id":"v_wBwIseDzyW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Processo de treino\n","# O input são as imagens com ruído e o target são as imagens originais\n","\n","autoencoder.fit(x_train_noisy, x_train,\n","                epochs=10,\n","                shuffle=True)"],"metadata":{"id":"luzAqOsFD4nO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Confirmar a redução de dimensionalidade até à obtenção da representação latente\n","# Confirmar a expansão feita pelo Decoder até às dimensões originais\n","\n","autoencoder.summary()\n","\n","print('***Encoder***')\n","autoencoder.encoder.summary()\n","\n","print('***Decoder***')\n","autoencoder.decoder.summary()"],"metadata":{"id":"qiwRnmNsEORd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Avaliação do desempenho no conjunto de teste\n","\n","autoencoder.evaluate(x_test_noisy, x_test)"],"metadata":{"id":"KGHP0a8xE5zH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Aplicar o modelo às imagens de teste com ruído\n","\n","encoded_imgs = autoencoder.encoder(x_test_noisy).numpy()\n","decoded_imgs = autoencoder.decoder(encoded_imgs).numpy()"],"metadata":{"id":"ea24PTqHFBNo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Comparar as imagens originais, as imagens com ruído e o resultado obtido pelo Autoencoder ao ser \n","# alimentado com as imagens com ruído\n","\n","n = 10\n","plt.figure(figsize=(20, 10))\n","for i in range(n):\n","\n","    # display original\n","    ax = plt.subplot(3, n, i + 1)\n","    plt.title(\"Originais\")\n","    plt.imshow(tf.squeeze(x_test[i+start]))\n","    plt.gray()\n","    ax.get_xaxis().set_visible(False)\n","    ax.get_yaxis().set_visible(False)\n","    \n","    # display original + noise\n","    ax = plt.subplot(3, n, i + n + 1)\n","    plt.title(\"Com Ruído\")\n","    plt.imshow(tf.squeeze(x_test_noisy[i+start]))\n","    plt.gray()\n","    ax.get_xaxis().set_visible(False)\n","    ax.get_yaxis().set_visible(False)\n","\n","    # display reconstruction\n","    bx = plt.subplot(3, n, i + n*2 + 1)\n","    plt.title(\"Denoised\")\n","    plt.imshow(tf.squeeze(decoded_imgs[i+start]))\n","    plt.gray()\n","    bx.get_xaxis().set_visible(False)\n","    bx.get_yaxis().set_visible(False)\n","plt.show()"],"metadata":{"id":"sg8QGTrsFFv_"},"execution_count":null,"outputs":[]}]}